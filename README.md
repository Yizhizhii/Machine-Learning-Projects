**Tongji University's Fall Semester 2023 Machine Learning Course Projects.**We completed projects on three aspects: regression prediction, supervised learning classification, and unsupervised clustering. In Project 01, we manually implemented a simple linear regression algorithm model and conducted a longitudinal comparison of various existing machine learning methods to predict car prices. (Data source: https://www.kaggle.com/datasets/hellbuoy/car-price-prediction/data). In Project 02, we used techniques such as Bag of Words, TF-IDF, and word (sentence) vectorization to extract text features, and constructed multiple machine learning models, such as Support Vector Machines and Logistic Regression, for sentiment classification tasks. Moreover, we also explored and optimized training for deep learning models such as RNN, LSTM, and BERT, focusing on the interpretability of the models (Data source: https://huggingface.co/datasets/dair-ai/emotion). Project 03 aimed to explore and evaluate the application effects of different text clustering techniques on real-world datasets. We applied various models like TF-IDF, GloVe, Doc2Vec, and Transformer to extract text features, and then conducted unsupervised clustering using methods such as K-Means and hierarchical clustering. (Data source: http://qwone.com/~jason/20Newsgroups/).
During the Fall Semester of 2023, we, at Tongji University, embarked on machine learning course projects encompassing three principal areas: regression prediction, supervised learning classification, and unsupervised clustering.

- **Project 01** involved the manual development of a straightforward linear regression algorithm model. We also conducted a comprehensive comparison of various existing machine learning methods for predicting car prices. (Data source: [Kaggle - Car Price Prediction](https://www.kaggle.com/datasets/hellbuoy/car-price-prediction/data)).

- **Project 02**, we utilized techniques such as Bag of Words, TF-IDF, and word (sentence) vectorization to extract textual features. We then built several machine learning models, including Support Vector Machines and Logistic Regression, for performing sentiment classification tasks. Additionally, we delved into and optimized the training of deep learning models such as RNN, LSTM, and BERT, with a focus on the interpretability of these models. (Data source: [Hugging Face - Emotion Dataset](https://huggingface.co/datasets/dair-ai/emotion)).

- **Project 03** aimed at exploring and assessing the effectiveness of different text clustering techniques on real-world datasets. We employed a variety of models, including TF-IDF, GloVe, Doc2Vec, and Transformer, to extract textual features. Subsequently, we performed unsupervised clustering using methods like K-Means and hierarchical clustering. (Data source: [20 Newsgroups Dataset](http://qwone.com/~jason/20Newsgroups/)).

These projects provided us with a comprehensive understanding and hands-on experience in the fields of machine learning and deep learning, showcasing the practical applications of these technologies in analyzing and interpreting complex datasets.
